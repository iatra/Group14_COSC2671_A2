{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b806c4a-4249-4c84-a576-e7b87a7448db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "import csv\n",
    "import os\n",
    "\n",
    "final_data = []\n",
    "youtube = build('youtube', 'v3', developerKey='AIzaSyDO0CqgeMm9pfPegdwYGpUaBP0ud5ZlXuw') \n",
    "\n",
    "def fetch_videos_by_query(query, region_code=None, category_id=None, is_live=False):\n",
    "    videos_data = []\n",
    "    try:\n",
    "        published_after = '2022-05-01T00:00:00Z'\n",
    "        published_before = '2025-05-10T00:00:00Z'\n",
    "        next_page_token = None\n",
    "        videos_fetched = 0;\n",
    "        while True:\n",
    "            search_response = youtube.search().list(\n",
    "                q=query,\n",
    "                part='snippet',\n",
    "                maxResults=50,\n",
    "                type='video',\n",
    "                publishedAfter=published_after,\n",
    "                publishedBefore=published_before,\n",
    "                regionCode=region_code if region_code else None,\n",
    "                videoCategoryId=category_id if category_id else None,\n",
    "                order='date',\n",
    "                pageToken=next_page_token\n",
    "            ).execute()\n",
    "\n",
    "            for item in search_response.get('items', []):\n",
    "                video_id = item['id']['videoId']\n",
    "                video_title = item['snippet']['title']\n",
    "                video_details = fetch_video_details(video_id)\n",
    "                comments = fetch_comments(video_title, video_id)\n",
    "                videos_data.append({\n",
    "                    'video_id': video_id,\n",
    "                    'video_title': video_title,\n",
    "                    'video_details': video_details,\n",
    "                    'comments': comments\n",
    "                })\n",
    "                videos_fetched += 1\n",
    "                print(f\"videos_fetched so far: {videos_fetched}\")\n",
    "            next_page_token = search_response.get('nextPageToken')\n",
    "            if not next_page_token:\n",
    "                break\n",
    "\n",
    "    except HttpError as e:\n",
    "        print(f\"Failed to retrieve videos: {e}\")\n",
    "\n",
    "    final_data.extend(videos_data)\n",
    "\n",
    "def fetch_video_details(video_id):\n",
    "    try:\n",
    "        video_response = youtube.videos().list(\n",
    "            part='snippet,contentDetails,statistics',\n",
    "            id=video_id\n",
    "        ).execute()\n",
    "        video_details = []\n",
    "        for video in video_response.get('items', []):\n",
    "            video_details.append({\n",
    "                'view_count': video['statistics'].get('viewCount', 'N/A'),\n",
    "                'like_count': video['statistics'].get('likeCount', 'N/A'),\n",
    "                'comment_count': video['statistics'].get('commentCount', 'N/A')\n",
    "            })\n",
    "        return video_details\n",
    "    except HttpError as e:\n",
    "        print(f\"Failed to retrieve video details for video ID '{video_id}': {e}\")\n",
    "        return None\n",
    "\n",
    "def fetch_comments(video_title, video_id, min_comments=2000, min_replies=1000):\n",
    "    comments_data = []\n",
    "    comments_collected = 0\n",
    "    replies_collected = 0\n",
    "    try:\n",
    "        next_page_token = None\n",
    "        while comments_collected < min_comments or replies_collected < min_replies:\n",
    "            comments_response = youtube.commentThreads().list(\n",
    "                part='snippet,replies',\n",
    "                videoId=video_id,\n",
    "                maxResults=100,\n",
    "                pageToken=next_page_token\n",
    "            ).execute()\n",
    "\n",
    "            for comment_thread in comments_response.get('items', []):\n",
    "                top_comment = comment_thread['snippet']['topLevelComment']\n",
    "                comment_text = top_comment['snippet']['textDisplay']\n",
    "                commenter_name = top_comment['snippet']['authorDisplayName']\n",
    "                timestamp = top_comment['snippet']['publishedAt']\n",
    "\n",
    "                # For top-level comments, parent is None or empty\n",
    "                comments_data.append([video_title, commenter_name, comment_text, timestamp, 'Comment', '', video_id])\n",
    "                comments_collected += 1\n",
    "\n",
    "                # Replies to the top-level comment\n",
    "                if 'replies' in comment_thread:\n",
    "                    for reply in comment_thread['replies']['comments']:\n",
    "                        reply_text = reply['snippet']['textDisplay']\n",
    "                        replier_name = reply['snippet']['authorDisplayName']\n",
    "                        reply_timestamp = reply['snippet']['publishedAt']\n",
    "                        # The parent for the reply is the top-level commenter\n",
    "                        comments_data.append([video_title, replier_name, reply_text, reply_timestamp, 'Reply', commenter_name, video_id])\n",
    "                        replies_collected += 1\n",
    "                        if replies_collected >= min_replies:\n",
    "                            break\n",
    "\n",
    "            next_page_token = comments_response.get('nextPageToken')\n",
    "            if not next_page_token or comments_collected >= min_comments:\n",
    "                break\n",
    "\n",
    "    except HttpError as e:\n",
    "        if e.resp.status == 403 and 'commentsDisabled' in str(e):\n",
    "            print(f\"Comments are disabled for video title '{video_title}' (ID: {video_id}). Skipping...\")\n",
    "        else:\n",
    "            print(f\"Failed to retrieve comments for video title '{video_title}': {e}\")\n",
    "\n",
    "    return comments_data\n",
    "\n",
    "def write_to_csv(data):\n",
    "    file_name = 'youtube_data_data.csv'\n",
    "    with open(file_name, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Video ID', 'Video Title', 'View Count', 'Like Count', 'Comment Count',\n",
    "                         'Commenter Name', 'Text', 'Timestamp', 'Type', 'Parent'])\n",
    "        for video in data:\n",
    "            for comment in video['comments']:\n",
    "                writer.writerow([\n",
    "                    video['video_id'],\n",
    "                    video['video_title'],\n",
    "                    video['video_details'][0]['view_count'] if video['video_details'] else 'N/A',\n",
    "                    video['video_details'][0]['like_count'] if video['video_details'] else 'N/A',\n",
    "                    video['video_details'][0]['comment_count'] if video['video_details'] else 'N/A',\n",
    "                    comment[1],  # Commenter Name\n",
    "                    comment[2],  # Text\n",
    "                    comment[3],  # Timestamp\n",
    "                    comment[4],  # Type (Comment/Reply)\n",
    "                    comment[5],  # Parent\n",
    "                ])\n",
    "\n",
    "    file_path = os.path.abspath(file_name)\n",
    "    print(f\"CSV file saved at: {file_path}\")\n",
    "\n",
    "queries = [\n",
    "    \"Vline vs Metro\",\n",
    "    \"Comparision between Metro and Vline Train\",\n",
    "    \"Regional vs Metropolitan Train\",\n",
    "    \"Melbourne Trains\"\n",
    "]\n",
    "for q in queries:\n",
    "    fetch_videos_by_query(q, region_code='AU')\n",
    "write_to_csv(final_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
